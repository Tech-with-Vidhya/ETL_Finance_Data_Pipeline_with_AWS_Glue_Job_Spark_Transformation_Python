# ETL_Finance_Data_Pipeline_with_AWS_Glue_Job_Spark_Transformation_Python

This project covers the implementation of building a ETL data pipeline using Python and AWS Services with a Spark transformation job for financial stocks trade transactions.  

The Spark Transformation Job implemented using Python PySpark transforms the trade transactions data stored in the AWS S3 Bucket; to filter a sub-set of trade transactions for which the total number of shares transacted are less than or equal to 100.  

Tools & Technologies: 
1. Python
2. Boto3 SDK
3. PySpark
4. AWS Command Line Interface (CLI) 
5. AWS Virtual Private Cloud (VPC)
6. AWS VPC Endpoint
7. AWS S3
8. AWS Glue
9. AWS Glue Crawler
10. AWS Glue Jobs
11. AWS Athena
12. AWS Redshift
13. Spark
